{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# AIC-25 Colab: Textual KIS (Clean Flow)\n",
    "\n",
    "Choose one path and follow the numbered steps.\n",
    "\n",
    "- Path A ‚Äî Quickstart (use provided features): simplest, fastest\n",
    "- Path B ‚Äî Recompute (SigLIP2): higher quality, recomputes features and model\n",
    "\n",
    "Steps overview\n",
    "1) Clone repo\n",
    "2) Install deps\n",
    "3) Download dataset\n",
    "4A) Quickstart setup (Path A) ‚Äî OR ‚Äî 4B) Recompute SigLIP2 (Path B)\n",
    "5) Start backend\n",
    "6) Run a KIS query and export CSV\n",
    "7) Zip for Codabench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "choose_path"
   },
   "outputs": [],
   "source": "# Environment detection and directory setup\nimport os\nimport sys\n\n# CRITICAL: Set memory management BEFORE any PyTorch imports\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\n# Detect environment and set base directory\nif 'google.colab' in sys.modules:\n    # Google Colab environment\n    BASE_DIR = '/content/aic-25'\n    print('Environment: Google Colab')\nelse:\n    # Local Jupyter/Linux environment - assume we're in the project root\n    # or create a local aic-25 directory structure\n    current_dir = os.path.abspath('.')\n    \n    # Check if we're already in the project root (has tools, aic-24-BE, etc.)\n    if all(os.path.exists(os.path.join(current_dir, d)) for d in ['tools', 'aic-24-BE', 'aic-24-FE']):\n        BASE_DIR = current_dir\n        print(f'Environment: Local Jupyter (already in project root)')\n    else:\n        # Create a local workspace directory\n        BASE_DIR = os.path.join(current_dir, 'aic-25-local')\n        os.makedirs(BASE_DIR, exist_ok=True)\n        print(f'Environment: Local Jupyter (created workspace)')\n\nprint(f'Base directory: {BASE_DIR}')\n\n# Choose your path: 'quickstart' or 'recompute'\nPATH_CHOICE = 'recompute'  # <-- set to 'quickstart' for the simplest path\nprint('Path:', PATH_CHOICE)\n\n# Check GPU memory early to detect if kernel restart is needed\ntry:\n    import torch\n    if torch.cuda.is_available():\n        free_gb = torch.cuda.mem_get_info()[0] / 1024**3\n        total_gb = torch.cuda.mem_get_info()[1] / 1024**3\n        used_gb = total_gb - free_gb\n        print(f'\\nüîß GPU Memory Status:')\n        print(f'  Total: {total_gb:.2f}GB')\n        print(f'  Used:  {used_gb:.2f}GB ({used_gb/total_gb*100:.1f}%)')\n        print(f'  Free:  {free_gb:.2f}GB ({free_gb/total_gb*100:.1f}%)')\n        \n        if used_gb > total_gb * 0.8:  # More than 80% used\n            print(f'‚ö†Ô∏è  WARNING: GPU memory is {used_gb/total_gb*100:.1f}% full!')\n            print(f'üí° Consider restarting your Python kernel to free GPU memory')\n            print(f'   (Kernel ‚Üí Restart Kernel... in Jupyter)')\n        elif free_gb < 4:\n            print(f'‚ö†Ô∏è  WARNING: Only {free_gb:.2f}GB free - may need smaller batch sizes')\n    else:\n        print('üîß CUDA not available, will use CPU')\nexcept ImportError:\n    print('üîß PyTorch not yet imported, will check memory later')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": "# Step 1) Setup repository structure\nimport os, shutil, subprocess\n\nif 'google.colab' in sys.modules:\n    # Google Colab: Clone repository\n    REPO_URL = 'https://github.com/dnlqvu/hcm-AI-challenge-2024-main.git'\n    if os.path.exists(BASE_DIR):\n        shutil.rmtree(BASE_DIR)\n    print('Cloning', REPO_URL, '->', BASE_DIR)\n    subprocess.run(['git', 'clone', REPO_URL, BASE_DIR], check=True)\n    print('Repository contents:', os.listdir(BASE_DIR))\nelse:\n    # Local environment: Handle different scenarios\n    current_dir = os.path.abspath('.')\n    \n    if BASE_DIR == current_dir:\n        # We're already in the project root\n        print(f'‚úÖ Using existing project structure in {BASE_DIR}')\n        print('Contents:', [f for f in os.listdir(BASE_DIR) if not f.startswith('.')])\n    else:\n        # We're in a different directory, need to copy or clone\n        if os.path.exists('tools') and os.path.exists('aic-24-BE'):\n            # We have the source, copy to workspace\n            print(f'üìÅ Copying project files to workspace: {BASE_DIR}')\n            for item in ['tools', 'aic-24-BE', 'aic-24-FE']:\n                src = os.path.join(current_dir, item)\n                dst = os.path.join(BASE_DIR, item)\n                if os.path.exists(src):\n                    if os.path.exists(dst):\n                        shutil.rmtree(dst)\n                    shutil.copytree(src, dst)\n            print('‚úÖ Project structure copied to workspace')\n        else:\n            # Clone from repo\n            print(f'üîÑ Cloning repository to {BASE_DIR}')\n            if os.path.exists(BASE_DIR):\n                shutil.rmtree(BASE_DIR)\n            REPO_URL = 'https://github.com/dnlqvu/hcm-AI-challenge-2024-main.git'\n            subprocess.run(['git', 'clone', REPO_URL, BASE_DIR], check=True)\n            print('‚úÖ Repository cloned')\n        \n        print('Workspace contents:', os.listdir(BASE_DIR))\n\n# Verify the structure is correct\nrequired_dirs = ['tools', 'aic-24-BE']\nmissing_dirs = [d for d in required_dirs if not os.path.exists(os.path.join(BASE_DIR, d))]\nif missing_dirs:\n    raise FileNotFoundError(f'‚ùå Missing required directories in {BASE_DIR}: {missing_dirs}')\nprint('‚úÖ Repository structure verified')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd_root"
   },
   "outputs": [],
   "source": "# Change to project directory and show current location\nos.chdir(BASE_DIR)\nprint('Current working directory:', os.getcwd())\nprint('Contents:', [f for f in os.listdir('.') if not f.startswith('.')])\n\n# Step 2) Install backend + extractor dependencies\nbackend_dir = os.path.join(BASE_DIR, 'aic-24-BE')\nos.chdir(backend_dir)\nprint(f'Installing backend dependencies from {backend_dir}')\n\n# Check for newer GPU and install appropriate PyTorch\nimport subprocess\nimport sys\n\n# Check GPU and CUDA compatibility\ntry:\n    import torch\n    if torch.cuda.is_available():\n        gpu_name = torch.cuda.get_device_name(0)\n        print(f\"Detected GPU: {gpu_name}\")\n        \n        # Check if we have RTX 50 series or newer GPU\n        if \"5070\" in gpu_name or \"5080\" in gpu_name or \"5090\" in gpu_name or \"4090\" in gpu_name:\n            print(\"‚ö†Ô∏è Detected newer GPU, upgrading PyTorch for compatibility...\")\n            \n            # Uninstall old PyTorch\n            if 'google.colab' in sys.modules:\n                get_ipython().system('pip uninstall -y torch torchvision torchaudio')\n                # Install PyTorch 2.2+ with CUDA 12.1 support for newer GPUs\n                get_ipython().system('pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121')\n            else:\n                subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'torch', 'torchvision', 'torchaudio'], \n                              capture_output=True)\n                # Install PyTorch 2.2+ with CUDA 12.1 support\n                subprocess.run([sys.executable, '-m', 'pip', 'install', 'torch', 'torchvision', 'torchaudio', \n                               '--index-url', 'https://download.pytorch.org/whl/cu121'], check=True)\n            print(\"‚úÖ PyTorch upgraded for newer GPU support\")\nexcept ImportError:\n    print(\"PyTorch not yet installed, will install with requirements\")\n\n# Use appropriate pip installation method\nif 'google.colab' in sys.modules:\n    get_ipython().system('python -m pip install --quiet --upgrade pip')\n    get_ipython().system('pip install --quiet -r requirements.txt')\nelse:\n    # Local environment - use subprocess for better error handling\n    try:\n        subprocess.run([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip'], check=True)\n        subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt'], check=True)\n        print('‚úÖ Backend requirements installed successfully')\n    except subprocess.CalledProcessError as e:\n        print(f'‚ùå Failed to install requirements: {e}')\n        print('You may need to install requirements manually: pip install -r requirements.txt')\n\n# Check if critical packages installed successfully\nimport sys\ntry:\n    import uvicorn\n    import fastapi\n    print(\"‚úì Backend dependencies installed\")\nexcept ImportError as e:\n    print(f\"‚úó Backend dependency missing: {e}\")\n    sys.exit(1)\n\n# Return to base directory\nos.chdir(BASE_DIR)\n\n# Install extras with compatible versions\nprint(\"\\nInstalling additional dependencies with compatible versions...\")\nextra_packages = [\n    'opencv-python==4.8.1.78',  # Compatible with numpy 1.26.4\n    'tqdm', \n    'pillow', \n    'open_clip_torch'\n]\n\nfor pkg in extra_packages:\n    try:\n        print(f\"Installing {pkg}...\")\n        if 'google.colab' in sys.modules:\n            get_ipython().system(f'pip install --quiet {pkg}')\n        else:\n            result = subprocess.run([sys.executable, '-m', 'pip', 'install', pkg], \n                                  capture_output=True, text=True)\n            if result.returncode != 0 and 'already satisfied' not in result.stdout:\n                print(f'‚ö†Ô∏è Warning installing {pkg}: {result.stderr}')\n    except subprocess.CalledProcessError:\n        print(f'‚ö†Ô∏è Failed to install {pkg} - may need manual installation')\n\n# Verify extraction dependencies and CUDA compatibility\ntry:\n    import cv2\n    import open_clip\n    import torch\n    import numpy as np\n    \n    print(\"\\n=== System Status ===\")\n    print(f\"NumPy version: {np.__version__}\")\n    print(f\"OpenCV version: {cv2.__version__}\")\n    print(f\"PyTorch version: {torch.__version__}\")\n    \n    if torch.cuda.is_available():\n        print(f\"CUDA available: Yes\")\n        print(f\"CUDA version: {torch.version.cuda}\")\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        print(f\"GPU compute capability: {torch.cuda.get_device_capability(0)}\")\n        \n        # Test CUDA functionality\n        try:\n            test_tensor = torch.randn(2, 2).cuda()\n            result = test_tensor @ test_tensor.T\n            print(\"‚úì CUDA operations working correctly\")\n            device_info = 'cuda'\n        except RuntimeError as e:\n            print(f\"‚úó CUDA operations failed: {e}\")\n            print(\"‚ö†Ô∏è Falling back to CPU\")\n            device_info = 'cpu'\n    else:\n        print(\"CUDA available: No\")\n        device_info = 'cpu'\n    \n    print(f\"‚úì All dependencies installed (torch device: {device_info})\")\n    \nexcept ImportError as e:\n    print(f\"‚úó Extraction dependency missing: {e}\")\n    sys.exit(1)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Step 2) Install backend + extractor dependencies\n",
    "%cd /content/aic-25/aic-24-BE\n",
    "!python -m pip install --quiet --upgrade pip\n",
    "!pip install --quiet -r requirements.txt\n",
    "# Check if critical packages installed successfully\n",
    "import sys\n",
    "try:\n",
    "    import uvicorn\n",
    "    import fastapi\n",
    "    print(\"‚úì Backend dependencies installed\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚úó Backend dependency missing: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "%cd /content/aic-25\n",
    "# Extras for local extraction & utilities\n",
    "!pip install --quiet opencv-python tqdm pillow open_clip_torch\n",
    "# Verify extraction dependencies\n",
    "try:\n",
    "    import cv2\n",
    "    import open_clip\n",
    "    import torch\n",
    "    print(f\"‚úì Extraction dependencies installed (torch device: {'cuda' if torch.cuda.is_available() else 'cpu'})\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚úó Extraction dependency missing: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_csv"
   },
   "outputs": [],
   "source": "# Step 3) Upload AIC_2025_dataset_download_link.csv\nimport os\n\nif 'google.colab' in sys.modules:\n    # Google Colab: Use file upload widget\n    from google.colab import files\n    print('Please upload your AIC_2025_dataset_download_link.csv file:')\n    uploaded = files.upload()  # choose AIC_2025_dataset_download_link.csv\n    CSV_PATH = next(iter(uploaded))\n    print('Using uploaded CSV:', CSV_PATH)\nelse:\n    # Local environment: Look for CSV file or prompt for path\n    possible_paths = [\n        'AIC_2025_dataset_download_link.csv',\n        'dataset/AIC_2025_dataset_download_link.csv',\n        '../AIC_2025_dataset_download_link.csv',\n        os.path.expanduser('~/Downloads/AIC_2025_dataset_download_link.csv')\n    ]\n    \n    CSV_PATH = None\n    for path in possible_paths:\n        if os.path.exists(path):\n            CSV_PATH = path\n            print(f'‚úÖ Found dataset CSV at: {CSV_PATH}')\n            break\n    \n    if not CSV_PATH:\n        print('‚ùå AIC_2025_dataset_download_link.csv not found in common locations.')\n        print('Checked locations:', possible_paths)\n        CSV_PATH = input('Please enter the full path to AIC_2025_dataset_download_link.csv: ').strip()\n        if not os.path.exists(CSV_PATH):\n            raise FileNotFoundError(f'CSV file not found at: {CSV_PATH}')\n        print(f'‚úÖ Using CSV file: {CSV_PATH}')\n\nprint(f'Final CSV path: {os.path.abspath(CSV_PATH)}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_dataset"
   },
   "outputs": [],
   "source": "# Step 3) Download dataset assets to example_dataset/ and extract\nos.chdir(BASE_DIR)\nprint(f'Working in: {os.getcwd()}')\n\n# Create dataset directory\ndataset_dir = os.path.join(BASE_DIR, 'example_dataset')\nos.makedirs(dataset_dir, exist_ok=True)\n\nif 'google.colab' in sys.modules:\n    get_ipython().system(f'python tools/aic_cli.py download-dataset --csv {CSV_PATH} --outdir example_dataset --extract')\n    get_ipython().system('ls -la example_dataset | head -n 50')\nelse:\n    # Local environment - use subprocess\n    try:\n        cmd = [sys.executable, 'tools/aic_cli.py', 'download-dataset', \n               '--csv', CSV_PATH, '--outdir', 'example_dataset', '--extract']\n        print(f'Running: {\" \".join(cmd)}')\n        result = subprocess.run(cmd, check=True, capture_output=True, text=True, cwd=BASE_DIR)\n        print('‚úÖ Dataset download completed')\n        if result.stdout:\n            print('Output:', result.stdout[-500:])  # Last 500 chars\n    except subprocess.CalledProcessError as e:\n        print(f'‚ùå Dataset download failed: {e}')\n        if e.stderr:\n            print('Error:', e.stderr[-500:])\n        raise\n\n# Sanity checks for required directories\nrequired_dataset_dirs = [\n    'example_dataset/map-keyframes',\n    'example_dataset/clip-features-32', \n    'example_dataset/media-info',\n    'example_dataset/keyframes'\n]\n\nfor check_dir in required_dataset_dirs:\n    full_path = os.path.join(BASE_DIR, check_dir)\n    if not os.path.exists(full_path):\n        print(f'‚ö†Ô∏è MISSING: {check_dir}')\n    else:\n        print(f'‚úÖ Found: {check_dir}')\n\nprint(f'Dataset contents: {os.listdir(os.path.join(BASE_DIR, \"example_dataset\"))}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1fb281",
   "metadata": {
    "id": "pathA_quickstart"
   },
   "outputs": [],
   "source": "os.chdir(BASE_DIR)\nif PATH_CHOICE != 'recompute':\n    print('Skipping Recompute (PATH_CHOICE!=recompute)')\n    raise SystemExit(0)\n\nVIDEOS_DIR = os.path.join(BASE_DIR, 'example_dataset', 'Videos_L21_a')\nMODEL = 'ViT-L-16-SigLIP-256'  # Changed from 384 to avoid OOM\nPRETRAINED = 'webli'  # Correct pretrained tag for SigLIP models\nCLIP_LEN = 1.5\nDECODE_FPS = 1.5  # Reduced from 2.0 to save memory\nTARGET_FPS = 0.8  # Reduced from 1.0 to save memory\n\nprint(f'Videos directory: {VIDEOS_DIR}')\nprint(f'Videos directory exists: {os.path.exists(VIDEOS_DIR)}')\nif os.path.exists(VIDEOS_DIR):\n    print(f'Videos found: {os.listdir(VIDEOS_DIR)[:5]}')  # Show first 5\nprint(f'Model: {MODEL} with {PRETRAINED}')\n\n# 4B.1 Smart sampling ‚Üí extract exact frames (original indices) - with memory-optimized adaptive sampling\nframes_dir = os.path.join(BASE_DIR, 'aic-24-BE', 'data', 'video_frames')\nos.makedirs(frames_dir, exist_ok=True)\nprint(f'Frames directory: {frames_dir}')\n\n# Clear any existing GPU memory before starting\ntry:\n    import torch\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        import gc\n        gc.collect()\n        free_gb = torch.cuda.mem_get_info()[0] / 1024**3\n        total_gb = torch.cuda.mem_get_info()[1] / 1024**3\n        print(f'üîß GPU Memory cleared: {free_gb:.2f}GB free / {total_gb:.2f}GB total')\n        \n        if free_gb < 3:\n            print(f'üö® CRITICAL: Only {free_gb:.2f}GB free - strongly recommend restarting kernel!')\nexcept ImportError:\n    pass\n\ncmd = [\n    sys.executable, 'tools/aic_cli.py', 'sample-smart', \n    '--strategy', 'clip-delta',\n    '--videos-dir', VIDEOS_DIR,\n    '--frames-dir', frames_dir,\n    '--decode-fps', str(DECODE_FPS),\n    '--target-fps', str(TARGET_FPS),\n    '--model', MODEL,\n    '--pretrained', PRETRAINED,\n    '--adaptive',\n    '--batch-size', '2'  # Very conservative batch size to avoid OOM\n]\n\nprint(f'Running smart sampling: {\" \".join(cmd)}')\nif 'google.colab' in sys.modules:\n    get_ipython().system(f'python tools/aic_cli.py sample-smart --strategy clip-delta --videos-dir \"{VIDEOS_DIR}\" --frames-dir \"{frames_dir}\" --decode-fps {DECODE_FPS} --target-fps {TARGET_FPS} --model {MODEL} --pretrained {PRETRAINED} --adaptive --batch-size 2')\nelse:\n    try:\n        result = subprocess.run(cmd, cwd=BASE_DIR, check=True, capture_output=True, text=True)\n        print('‚úÖ Smart sampling completed')\n        if result.stdout:\n            print('Output:', result.stdout[-1000:])\n    except subprocess.CalledProcessError as e:\n        print(f'‚ùå Smart sampling failed with exit code {e.returncode}')\n        print(f'Command: {\" \".join(e.cmd)}')\n        if e.stdout:\n            print('STDOUT:')\n            print(e.stdout)\n        if e.stderr:\n            print('STDERR:')\n            print(e.stderr)\n        \n        # Don't raise the error, continue with manual approach\n        print('\\n‚ö†Ô∏è Falling back to direct smart_sampling.py execution...')\n\n# If we get here and smart sampling failed, try direct approach with even smaller batch size\nif not os.path.exists(frames_dir) or not os.listdir(frames_dir):\n    print('üîÑ Attempting direct smart_sampling.py execution with minimal batch size:')\n    direct_cmd = [\n        sys.executable, 'tools/smart_sampling.py',\n        '--videos-dir', VIDEOS_DIR,\n        '--strategy', 'clip-delta', \n        '--decode-fps', str(DECODE_FPS),\n        '--target-fps', str(TARGET_FPS),\n        '--model', MODEL,\n        '--pretrained', PRETRAINED,\n        '--adaptive',\n        '--batch-size', '1',  # Absolute minimum batch size\n        '--out-csv', 'selected_frames.csv'\n    ]\n    \n    try:\n        direct_result = subprocess.run(direct_cmd, cwd=BASE_DIR, check=True, capture_output=True, text=True)\n        print('‚úÖ Direct smart sampling completed')\n        \n        # Now extract frames using crop_frame.py\n        if os.path.exists('selected_frames.csv'):\n            crop_cmd = [\n                sys.executable, 'aic-24-BE/data_processing/crop_frame.py',\n                '--input-dir', VIDEOS_DIR,\n                '--output-dir', frames_dir,\n                '--frame-list', 'selected_frames.csv'\n            ]\n            crop_result = subprocess.run(crop_cmd, cwd=BASE_DIR, check=True, capture_output=True, text=True)\n            print('‚úÖ Frame extraction completed')\n    except subprocess.CalledProcessError as direct_e:\n        print(f'‚ùå Direct smart sampling also failed: {direct_e}')\n        if direct_e.stderr:\n            print('STDERR:', direct_e.stderr)\n        raise\n\n# 4B.2 Encode sampled frames with SigLIP-256 and write shards\nbackend_dir = os.path.join(BASE_DIR, 'aic-24-BE')\nos.chdir(backend_dir)\nprint(f'Working in backend directory: {os.getcwd()}')\n\nimport os, numpy as np, torch, pickle, gc\nfrom pathlib import Path\nfrom PIL import Image\nimport open_clip\nfrom tqdm import tqdm\n\n# Clear GPU memory before loading model\ntorch.cuda.empty_cache()\ngc.collect()\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Loading {MODEL} with {PRETRAINED} on {device}...\")\n\n# Memory monitoring\nif torch.cuda.is_available():\n    free_gb = torch.cuda.mem_get_info()[0] / 1024**3\n    total_gb = torch.cuda.mem_get_info()[1] / 1024**3\n    print(f\"GPU Memory before loading: {free_gb:.2f}GB free / {total_gb:.2f}GB total\")\n    \n    if free_gb < 2:\n        print(\"üö® CRITICAL: Less than 2GB free - model loading will likely fail!\")\n        print(\"üí° Please restart your Python kernel to free GPU memory\")\n\n# Clear any existing models from memory\nif 'model' in locals():\n    del model\ntorch.cuda.empty_cache()\ngc.collect()\n\nmodel, _, preprocess = open_clip.create_model_and_transforms(MODEL, pretrained=PRETRAINED, device=device)\nmodel.eval()\n\n# Memory monitoring after loading\nif torch.cuda.is_available():\n    free_gb = torch.cuda.mem_get_info()[0] / 1024**3\n    print(f\"GPU Memory after loading: {free_gb:.2f}GB free / {total_gb:.2f}GB total\")\n\nframes_root = 'data/video_frames'\nout_dir = 'data/clip_features'\nos.makedirs(out_dir, exist_ok=True)\n\n# Check if frames directory exists before proceeding\nif not os.path.exists(frames_root):\n    raise FileNotFoundError(f\"Frames directory not found: {frames_root}. Smart sampling may have failed.\")\n\ndef encode_batch(img_paths, target_size=256, batch_size=4):\n    \"\"\"Encode batch with ultra-conservative memory management\"\"\"\n    ims = []\n    for p in img_paths:\n        im = Image.open(p).convert('RGB')\n        # Resize to target resolution (256x256 for balance of context vs memory)\n        im = im.resize((target_size, target_size), Image.LANCZOS)\n        ims.append(preprocess(im))\n    \n    # Process in ultra-small sub-batches\n    all_feats = []\n    for i in range(0, len(ims), batch_size):\n        sub_batch = ims[i:i+batch_size]\n        try:\n            with torch.no_grad():\n                batch_tensor = torch.stack(sub_batch).to(device)\n                feats = model.encode_image(batch_tensor)\n                feats = feats / feats.norm(dim=-1, keepdim=True)\n                all_feats.append(feats.cpu().float().numpy())\n                \n                # Clear GPU cache after every sub-batch\n                if device == 'cuda':\n                    torch.cuda.empty_cache()\n        except torch.cuda.OutOfMemoryError:\n            print(f\"üö® OOM even with batch size {len(sub_batch)}! Processing one by one...\")\n            # Process individually\n            for single_tensor in sub_batch:\n                with torch.no_grad():\n                    single_batch = single_tensor.unsqueeze(0).to(device)\n                    feats = model.encode_image(single_batch)\n                    feats = feats / feats.norm(dim=-1, keepdim=True)\n                    all_feats.append(feats.cpu().float().numpy())\n                    torch.cuda.empty_cache()\n    \n    return np.concatenate(all_feats, axis=0)\n\n# Process videos with ultra-conservative memory management\ncheckpoint_dir = 'data/checkpoints'\nos.makedirs(checkpoint_dir, exist_ok=True)\n\nfor vid in sorted(os.listdir(frames_root)):\n    vid_dir = os.path.join(frames_root, vid)\n    if not os.path.isdir(vid_dir):\n        continue\n    \n    # Check for existing checkpoint\n    checkpoint_file = os.path.join(checkpoint_dir, f'{vid}.checkpoint')\n    final_file = os.path.join(out_dir, f'{vid}.pkl')\n    \n    if os.path.exists(final_file):\n        print(f\"Skipping {vid}: already processed\")\n        continue\n    \n    imgs = [f for f in os.listdir(vid_dir) if f.lower().endswith('.jpg')]\n    if not imgs:\n        continue\n    imgs = sorted(imgs, key=lambda x: int(os.path.splitext(x)[0]))\n    file_paths = [f'./data/video_frames/{vid}/{name}' for name in imgs]\n    \n    feats_list = []\n    bs = 8  # Ultra-conservative batch size\n    \n    start_idx = 0\n    if os.path.exists(checkpoint_file):\n        # Load checkpoint\n        with open(checkpoint_file, 'rb') as f:\n            checkpoint = pickle.load(f)\n            feats_list = checkpoint['feats_list']\n            start_idx = checkpoint['last_idx']\n        print(f\"Resuming {vid} from frame {start_idx}\")\n    \n    for i in tqdm(range(start_idx, len(imgs), bs), desc=f'Encoding {vid}'):\n        batch_paths = [os.path.join(vid_dir, name) for name in imgs[i:i+bs]]\n        batch_feats = encode_batch(batch_paths, batch_size=2)  # Ultra-small sub-batch\n        feats_list.append(batch_feats)\n        \n        # Save checkpoint every 20 frames (very frequent for safety)\n        if (i - start_idx) % 20 == 0 and i > start_idx:\n            with open(checkpoint_file, 'wb') as f:\n                pickle.dump({\n                    'feats_list': feats_list,\n                    'last_idx': i + bs\n                }, f)\n        \n        # Force garbage collection and memory cleanup after every batch\n        gc.collect()\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n            if i % 20 == 0:\n                free_gb = torch.cuda.mem_get_info()[0] / 1024**3\n                print(f\"  GPU Memory: {free_gb:.2f}GB free\")\n    \n    # Finalize features\n    feats_np = np.concatenate(feats_list, axis=0)\n    with open(final_file, 'wb') as f:\n        pickle.dump((file_paths, feats_np), f)\n    \n    # Clean up checkpoint\n    if os.path.exists(checkpoint_file):\n        os.remove(checkpoint_file)\n    \n    print(f\"‚úì Encoded {vid}: {feats_np.shape[0]} features at 256px resolution\")\n    \n# 4B.3 Build model and patch .env\nprint(\"Building NitzcheCLIP model...\")\nfrom nitzche_clip import NitzcheCLIP\nm = NitzcheCLIP(out_dir)\nos.makedirs('models', exist_ok=True)\nm.save('models/clip_siglip.pkl')\nenvp = Path('.env')\ncontent = envp.read_text(encoding='utf-8') if envp.exists() else ''\nlines = []\nsaw_path = saw_16 = False\nfor line in content.splitlines():\n    if line.strip().startswith('MODEL_PATH='): lines.append('MODEL_PATH=\"./models/\"'); saw_path=True\n    elif line.strip().startswith('MODEL_16='): lines.append('MODEL_16=\"clip_siglip.pkl\"'); saw_16=True\n    else: lines.append(line)\nif not saw_path: lines.append('MODEL_PATH=\"./models/\"')\nif not saw_16: lines.append('MODEL_16=\"clip_siglip.pkl\"')\n# Also set matching text encoder\nset_name = False; set_pre = False\nout=[]\nfor line in lines:\n    if line.strip().startswith('CLIP_MODEL_NAME='): out.append(f'CLIP_MODEL_NAME=\"{MODEL}\"'); set_name=True\n    elif line.strip().startswith('CLIP_PRETRAINED='): out.append(f'CLIP_PRETRAINED=\"{PRETRAINED}\"'); set_pre=True\n    else: out.append(line)\nif not set_name: out.append(f'CLIP_MODEL_NAME=\"{MODEL}\"')\nif not set_pre: out.append(f'CLIP_PRETRAINED=\"{PRETRAINED}\"')\nenvp.write_text('\\n'.join(out)+'\\n', encoding='utf-8')\nprint('‚úÖ Recompute complete. Ultra-memory-optimized smart-sampled frames + SigLIP-256 features with intelligent adaptive sampling. .env updated.')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start_backend"
   },
   "outputs": [],
   "source": "# Step 5) Start backend API (daemon)\nos.chdir(BASE_DIR)\nprint(f'Starting backend from: {os.getcwd()}')\n\n# Start backend using aic_cli\nif 'google.colab' in sys.modules:\n    get_ipython().system('python tools/aic_cli.py serve --port 8000 --run --daemon --no-reload')\n    get_ipython().system('python tools/aic_cli.py serve-status')\nelse:\n    # Local environment\n    try:\n        subprocess.Popen([sys.executable, 'tools/aic_cli.py', 'serve', '--port', '8000', '--run', '--daemon', '--no-reload'], \n                        cwd=BASE_DIR)\n        print('‚úÖ Backend started in daemon mode')\n        \n        # Check status\n        result = subprocess.run([sys.executable, 'tools/aic_cli.py', 'serve-status'], \n                              cwd=BASE_DIR, capture_output=True, text=True)\n        if result.stdout:\n            print('Status:', result.stdout.strip())\n    except Exception as e:\n        print(f'‚ùå Failed to start backend: {e}')\n\n# Test backend connectivity\nimport time, requests\nprint('Testing backend connectivity...')\nfor attempt in range(30):\n    try:\n        r = requests.get('http://localhost:8000/docs', timeout=2)\n        print(f'‚úÖ Backend reachable: HTTP {r.status_code}')\n        break\n    except Exception:\n        if attempt < 5:\n            print(f'Attempt {attempt + 1}: Waiting for backend...')\n        time.sleep(1)\nelse:\n    print('‚ùå Backend not reachable after 30 seconds')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_query"
   },
   "outputs": [],
   "source": [
    "# Step 6) Prepare a KIS query\n",
    "%cd /content/aic-25\n",
    "query_text = 'C·∫£nh quay b·∫±ng flycam m·ªôt c√¢y c·∫ßu ·ªü TP H·ªì Ch√≠ Minh, ti·∫øp theo ƒë·∫øn c·∫£nh quay t√≤a nh√† Bitexco. M·ªôt v√†i c·∫£nh sau ƒë√≥ chuy·ªÉn qua quay h√¨nh ·∫£nh h·ªì g∆∞∆°m t·∫°i H√† N·ªôi.'  # edit your KIS query here\n",
    "print('Query:', (query_text[:120] + ('...' if len(query_text) > 120 else '')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_kis"
   },
   "outputs": [],
   "source": "# Step 6) Export KIS CSV to submission/\nos.chdir(BASE_DIR)\nquery_text = 'C·∫£nh quay b·∫±ng flycam m·ªôt c√¢y c·∫ßu ·ªü TP H·ªì Ch√≠ Minh, ti·∫øp theo ƒë·∫øn c·∫£nh quay t√≤a nh√† Bitexco. M·ªôt v√†i c·∫£nh sau ƒë√≥ chuy·ªÉn qua quay h√¨nh ·∫£nh h·ªì g∆∞∆°m t·∫°i H√† N·ªôi.'\nprint('Query:', (query_text[:120] + ('...' if len(query_text) > 120 else '')))\n\nsubmission_dir = os.path.join(BASE_DIR, 'submission')\nos.makedirs(submission_dir, exist_ok=True)\n\nexport_cmd = [\n    sys.executable, 'tools/aic_cli.py', 'export',\n    '--text', query_text,\n    '--task', 'kis',\n    '--name', 'query-1',\n    '--api', 'http://localhost:8000',\n    '--outdir', 'submission',\n    '--wait-api', '30'\n]\n\nprint('Exporting KIS query results...')\nif 'google.colab' in sys.modules:\n    get_ipython().system(f'python tools/aic_cli.py export --text \"{query_text}\" --task kis --name query-1 --api http://localhost:8000 --outdir submission --wait-api 30')\n    get_ipython().system('echo \"Generated files:\" && ls -la submission')\n    get_ipython().system('echo \"Preview:\" && head -n 5 submission/query-1-kis.csv')\nelse:\n    try:\n        result = subprocess.run(export_cmd, cwd=BASE_DIR, check=True, capture_output=True, text=True)\n        print('‚úÖ Export completed successfully')\n        \n        # Show generated files\n        files = os.listdir(submission_dir)\n        print(f'Generated files: {files}')\n        \n        # Preview the CSV\n        csv_file = os.path.join(submission_dir, 'query-1-kis.csv')\n        if os.path.exists(csv_file):\n            with open(csv_file, 'r') as f:\n                print('Preview:')\n                for i, line in enumerate(f):\n                    if i >= 5:\n                        break\n                    print(line.strip())\n        \n    except subprocess.CalledProcessError as e:\n        print(f'‚ùå Export failed: {e}')\n        if e.stderr:\n            print('Error:', e.stderr)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zip_submit"
   },
   "outputs": [],
   "source": "# Step 7) Zip for Codabench\nos.chdir(BASE_DIR)\nprint(f'Creating submission zip from: {os.getcwd()}')\n\nzip_cmd = [\n    sys.executable, 'tools/aic_cli.py', 'zip-submission',\n    '--outdir', 'submission',\n    '--name', 'aic25_submission.zip'\n]\n\nif 'google.colab' in sys.modules:\n    get_ipython().system('python tools/aic_cli.py zip-submission --outdir submission --name aic25_submission.zip')\n    from google.colab import files as colab_files\n    colab_files.download('aic25_submission.zip')\nelse:\n    try:\n        result = subprocess.run(zip_cmd, cwd=BASE_DIR, check=True, capture_output=True, text=True)\n        print('‚úÖ Submission zip created successfully')\n        \n        zip_path = os.path.join(BASE_DIR, 'aic25_submission.zip')\n        if os.path.exists(zip_path):\n            file_size = os.path.getsize(zip_path) / (1024 * 1024)  # MB\n            print(f'üì¶ Submission file: {zip_path} ({file_size:.2f} MB)')\n            print('Ready for upload to Codabench!')\n        else:\n            print('‚ùå Zip file not found after creation')\n            \n    except subprocess.CalledProcessError as e:\n        print(f'‚ùå Zip creation failed: {e}')\n        if e.stderr:\n            print('Error:', e.stderr)"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}